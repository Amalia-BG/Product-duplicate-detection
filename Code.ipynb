{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0kWe7mcmL1FT"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBBRiYwprq9x"
      },
      "source": [
        "# **Functions to run before Main**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6Y0Ti9HET4v"
      },
      "source": [
        "## Get All Brands"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOHpdu_2G5l6"
      },
      "outputs": [],
      "source": [
        "def get_brand_values(data_id):\n",
        "    count_brand = sum(1 for product in data_id if 'Brand' in product.get('featuresMap', {}))\n",
        "    #print(count_brand)\n",
        "    # Extract values associated with the 'Brand' key\n",
        "    brand_values = {\n",
        "        product['featuresMap']['Brand']\n",
        "        for product in data_id\n",
        "        if 'Brand' in product.get('featuresMap', {})\n",
        "    }\n",
        "\n",
        "    # Convert back to list\n",
        "    brand_values = list(brand_values)\n",
        "    return brand_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BplIb6Ofnfbq"
      },
      "source": [
        "# Clean the data and normalize the units"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yV8o216adT10"
      },
      "source": [
        "# (Original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnclIdXrdV9D"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def clean_and_normalize_original(text):\n",
        "\n",
        "    # Replace unit forms with standardized units\n",
        "    standard_inch = ['Inch', 'inches', '”', '-inch', ' inch', 'inch']\n",
        "    standard_hz = ['HERTZ', 'hertz', 'Hz', 'HZ', ' hz' '-hz', 'hz']\n",
        "\n",
        "    text = text.replace('\"','inch')\n",
        "\n",
        "    for element in standard_inch:\n",
        "      text =  text.replace(element, \"inch\")\n",
        "\n",
        "    for element in standard_hz:\n",
        "      text =  text.replace(element, \"hz\")\n",
        "\n",
        "    # Convert to lower case\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove any non-alphanumeric token in front of units inch and hz\n",
        "    text = re.sub(r'[^\\w]+(?=\\s*(inch|hz))', '', text)\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "example_text = 'Newegg.com - Refurbished: Samsung 46\" Class (45.9\" Diag.) 1080p 240 [Hz LED HDTV UN46ES6580'\n",
        "\n",
        "cleaned_text = clean_and_normalize_original(example_text)\n",
        "print(cleaned_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDJOo-gTjkuf"
      },
      "source": [
        "# (\"Novel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I3sf-yIvjhIt"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "def clean_and_normalize_novel(text):\n",
        "\n",
        "    # Replace unit forms with standardized units\n",
        "    standard_inch = ['-inch', 'Inch', 'inches', '”', '-inch', ' inch', 'INCH', 'Inches']\n",
        "    standard_hz = ['-hz', 'hertz', 'hz', 'HERTZ', 'Hertz', 'HZ', '-HZ', 'Hz']\n",
        "    standard_lbs = ['lbs', 'lb', 'pounds']\n",
        "    standard_w = ['watt', 'watts', 'w', 'W']\n",
        "    standard_v = ['volt', 'volts', 'v', 'V']\n",
        "\n",
        "    text = text.replace('\"','inch')\n",
        "\n",
        "    # lower case\n",
        "    text = text.lower()\n",
        "\n",
        "    for element in standard_inch:\n",
        "      text =  text.replace(element, \"inch\")\n",
        "\n",
        "    for element in standard_hz:\n",
        "      text =  text.replace(element, \"hz\")\n",
        "\n",
        "    for element in standard_lbs:\n",
        "      text =  text.replace(element, \"lbs\")\n",
        "\n",
        "    for element in standard_w:\n",
        "      text =  text.replace(element, \"w\")\n",
        "\n",
        "    for element in standard_v:\n",
        "      text =  text.replace(element, \"v\")\n",
        "\n",
        "\n",
        "    # Remove any non-alphanumeric token in front of units inch and hz\n",
        "    text = re.sub(r'[^\\w]+(?=\\s*(hz|inch|lbs|w|v))', ' ', text)\n",
        "\n",
        "########################################################################################\n",
        "\n",
        "    # Attach numbers to their adjacent units (e.g., \"28 hz\" -> \"28hz\")\n",
        "    # Regular expression pattern to match a number followed by a unit\n",
        "    pattern = r'(\\d+(\\.\\d+)?)\\s?(hz|inch|w|lbs|v)'\n",
        "    text = re.sub(pattern, r'\\1\\3', text)\n",
        "\n",
        "    # Remove special characters\n",
        "    # Regular expression to remove non-alphabetic characters before the decimal number + unit combination\n",
        "    pattern1 = r'([^a-zA-Z0-9\\s.])(\\d+\\.\\d+)(inch|w|lbs|hz)'\n",
        "    text = re.sub(pattern1, r'\\2\\3', text)\n",
        "\n",
        "    # Regular expression to remove non-alphabetic characters before the integer number + unit combination\n",
        "    pattern2 = r'([^a-zA-Z0-9\\s.])(\\d+)(inch|w|lbs|hz)'\n",
        "    text = re.sub(pattern2, r'\\2\\3', text)\n",
        "\n",
        "    # Remove parantheses\n",
        "    # Pattern to match parentheses and brackets\n",
        "    pattern = r'[\\(\\)\\[\\]]'\n",
        "    text = re.sub(pattern, '', text)\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "example_text = 'Newegg.com - Refurbished: Samsung 46\" Class (45.9\" Diag.) 1080p 240 [Hz LED HDTV UN46ES6580 SunBriteTV Signature 46\\\" Class 46\\\" Diag. LCD TV 1080p HDTV 1080p White 4660HD - Best Buy'\n",
        "\n",
        "cleaned_text = clean_and_normalize_novel(example_text)\n",
        "print(cleaned_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0asTzf6VERN8"
      },
      "source": [
        "# Extract model words from both Title and Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CF3EHxHEZzj"
      },
      "source": [
        "# (Original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eap77ghFEeia"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def extract_model_words_from_title_original(title):\n",
        "\n",
        "    # Clean and normalize title\n",
        "    title = clean_and_normalize_original(title)\n",
        "    #print(title)\n",
        "\n",
        "    # Regex to identify model-like patterns\n",
        "    model_words = re.findall(r'([a-zA-Z0-9]*(([0-9]+[^0-9, ]+)|([^0-9, ]+[0-9]+))[a-zA-Z0-9]*)', title)\n",
        "    #print(model_words)\n",
        "\n",
        "    # Extract only the matched groups\n",
        "    extracted_words = {match[0] for match in model_words}\n",
        "    return extracted_words\n",
        "\n",
        "\n",
        "def extract_model_words_from_kvp_original(features_map):\n",
        "\n",
        "    # Combine all feature values into a single string\n",
        "    features_combined = ' '.join(features_map.values())\n",
        "\n",
        "    kvp_model_words = re.findall(r'(\\d+\\.\\d+)[a-zA-Z]*\\b', features_combined)\n",
        "\n",
        "    # Use a set to store unique matches\n",
        "    extracted_words = set(kvp_model_words)\n",
        "\n",
        "    return extracted_words\n",
        "\n",
        "\n",
        "def extract_model_words_original_BOTH(data):\n",
        "\n",
        "    mw_per_product = []\n",
        "\n",
        "    for entry in data:  # Directly iterate over the list of product entries\n",
        "        # Extract model words from the title\n",
        "        title = entry.get('title', '')  # Extract the title of each product\n",
        "        title_words = extract_model_words_from_title_original(title)\n",
        "\n",
        "        # Extract model words from the key-value pairs\n",
        "        features_map = entry.get('featuresMap', {})\n",
        "        kvp_words = extract_model_words_from_kvp_original(features_map)\n",
        "\n",
        "        # Combine all extracted model words for the product\n",
        "        combined_model_words = title_words.union(kvp_words)\n",
        "        mw_per_product.append(combined_model_words)\n",
        "\n",
        "    #print(mw_per_product)\n",
        "    return mw_per_product"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3ZXeANPnmRL"
      },
      "source": [
        "# (Novel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Z04ONfbnzi4"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def extract_model_words_from_title_novel(title):\n",
        "\n",
        "    # Clean and normalize title\n",
        "    title = clean_and_normalize_novel(title)\n",
        "    #print(title)\n",
        "\n",
        "    # Regex to identify model-like patterns\n",
        "    model_words = re.findall(r'([a-zA-Z0-9]*(([0-9]+[^0-9, ]+)|([^0-9, ]+[0-9]+))[a-zA-Z0-9]*)', title)\n",
        "    #print(model_words)\n",
        "\n",
        "    # Extract only the matched groups\n",
        "    extracted_words = {match[0] for match in model_words}\n",
        "    return extracted_words\n",
        "\n",
        "\n",
        "def extract_model_words_from_kvp_novel(features_map):\n",
        "\n",
        "    # Combine all feature values into a single string\n",
        "    features_combined = ' '.join(features_map.values())\n",
        "    #print(features_combined)\n",
        "\n",
        "    kvp_model_words = re.findall(r'(\\d+\\.\\d+)[a-zA-Z]*\\b', features_combined)\n",
        "\n",
        "\n",
        "    # Count occurrences of each word\n",
        "    #word_counts = Counter(kvp_model_words)\n",
        "    # Filter out words that occur only once\n",
        "    #filtered_words = {word for word, count in word_counts.items() if count > 1}\n",
        "    #kvp_model_words = filtered_words\n",
        "\n",
        "    # Use a set to store unique matches\n",
        "    extracted_words = set(kvp_model_words)\n",
        "\n",
        "    return extracted_words\n",
        "\n",
        "\n",
        "################################################### Novelty:\n",
        "def extract_model_words_from_brand(features_map):\n",
        "\n",
        "    # Get the value of the 'Brand' key or return an empty string if not found\n",
        "    return features_map.get('Brand', '').lower()\n",
        "###########################################\n",
        "\n",
        "\n",
        "def extract_model_words_novel_BOTH(data):\n",
        "\n",
        "    mw_per_product = []\n",
        "\n",
        "    for entry in data:  # Iterate over the list of product entries\n",
        "        # Extract model words from the title\n",
        "        title = entry.get('title', '')  # Extract the title of each product\n",
        "        title_words = extract_model_words_from_title_novel(title)\n",
        "\n",
        "        # Extract model words from the key-value pairs\n",
        "        features_map = entry.get('featuresMap', {})\n",
        "        kvp_words = extract_model_words_from_kvp_novel(features_map)\n",
        "        #print(kvp_words)\n",
        "\n",
        "        # Extract brand value and ensure it is treated as a lowercase word\n",
        "        brand_value = extract_model_words_from_brand(features_map)\n",
        "        brand_words = {brand_value} if brand_value else set()  # Add brand to set only if not empty\n",
        "\n",
        "        # Combine all extracted model words for the product\n",
        "        #combined_model_words = title_words.union(kvp_words).union(brand_words)\n",
        "        combined_model_words = title_words.union(brand_words)\n",
        "        #combined_model_words = title_words.union(kvp_words)\n",
        "\n",
        "        # Add the combined model words for the current product to the list\n",
        "        mw_per_product.append(combined_model_words)\n",
        "\n",
        "    #print(mw_per_product)\n",
        "    return mw_per_product\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZjDR7Agn3Gi"
      },
      "source": [
        "# Binary Vectors (Matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLDCU3o8vsXx"
      },
      "outputs": [],
      "source": [
        "def get_binary_matrix(data, mw_per_product):\n",
        "\n",
        "    # Step 1: Collect all unique model words across all products\n",
        "    all_model_words = set()\n",
        "    for mw_set in mw_per_product:\n",
        "        all_model_words.update(mw_set)\n",
        "\n",
        "    # Convert the set of all model words into a list for consistent ordering\n",
        "    model_words_list = sorted(all_model_words)\n",
        "\n",
        "    # Step 2: Initialize binary matrix\n",
        "    num_products = len(data)\n",
        "    num_model_words = len(model_words_list)\n",
        "    print(f\"Number of products: {num_products}\")\n",
        "    print(f\"Number of model words: {num_model_words}\")\n",
        "\n",
        "    binary_matrix = np.zeros((num_products, num_model_words), dtype=int)\n",
        "\n",
        "    # Step 3: Populate the binary matrix\n",
        "    for i, mw_set in enumerate(mw_per_product):\n",
        "        for mw in mw_set:\n",
        "            if mw in model_words_list:\n",
        "                # Find the index of the model word in the model_words_list\n",
        "                mw_index = model_words_list.index(mw)\n",
        "                binary_matrix[i][mw_index] = 1\n",
        "\n",
        "    return binary_matrix, model_words_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pk9ZeecNbLOB"
      },
      "source": [
        "# Binary matrix with extra brand influence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-i7tzN64bPWY"
      },
      "outputs": [],
      "source": [
        "def get_binary_matrix_with_brand_influence(data, mw_per_product, brand_factor, data_id):\n",
        "\n",
        "    # Step 1: Collect all unique model words across all products\n",
        "    all_model_words = set()\n",
        "    for mw_set in mw_per_product:\n",
        "        all_model_words.update(mw_set)\n",
        "\n",
        "    # Convert the set of all model words into a list for consistent ordering\n",
        "    model_words_list = sorted(all_model_words)\n",
        "\n",
        "    # Step 2: Extract brand values using the existing function\n",
        "    brand_values = get_brand_values(data_id)\n",
        "    brand_values = [brand.lower() for brand in brand_values]  # Ensure consistency in case matching\n",
        "\n",
        "    # Step 3: Duplicate brand columns by the specified factor\n",
        "    extended_model_words_list = []\n",
        "    for mw in model_words_list:\n",
        "        extended_model_words_list.append(mw)\n",
        "        if mw in brand_values:\n",
        "            # Add duplicates of brand words\n",
        "            extended_model_words_list.extend([f\"{mw}_dup{i}\" for i in range(1, brand_factor)])\n",
        "\n",
        "    # Step 4: Initialize binary matrix\n",
        "    num_products = len(data)\n",
        "    num_model_words = len(extended_model_words_list)\n",
        "    print(f\"Number of products: {num_products}\")\n",
        "    print(f\"Number of model words (with brand influence): {num_model_words}\")\n",
        "\n",
        "    binary_matrix = np.zeros((num_products, num_model_words), dtype=int)\n",
        "\n",
        "    # Step 5: Populate the binary matrix\n",
        "    for i, mw_set in enumerate(mw_per_product):\n",
        "        for mw in mw_set:\n",
        "            # Add original model word columns\n",
        "            if mw in extended_model_words_list:\n",
        "                original_index = extended_model_words_list.index(mw)\n",
        "                binary_matrix[i][original_index] = 1\n",
        "\n",
        "                # Populate duplicated brand columns\n",
        "                if mw in brand_values:\n",
        "                    for j in range(1, brand_factor):\n",
        "                        dup_index = extended_model_words_list.index(f\"{mw}_dup{j}\")\n",
        "                        binary_matrix[i][dup_index] = 1\n",
        "\n",
        "    return binary_matrix, extended_model_words_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68HA4--ZMTDV"
      },
      "source": [
        "### Extra: Cut the columns (model words) which occur only once (Not used)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uifFYCLKqxQK"
      },
      "outputs": [],
      "source": [
        "def filter_binary_matrix(binary_matrix):\n",
        "    # Step 1: Count occurrences of each model word\n",
        "    column_sums = np.sum(binary_matrix, axis=0)\n",
        "\n",
        "# Step 2: Identify columns to keep (where occurrences > 1)\n",
        "    columns_to_keep = column_sums > 1\n",
        "\n",
        "# Step 3: Filter binary matrix to remove columns where sum is 1\n",
        "    filtered_binary_matrix = binary_matrix[:, columns_to_keep]\n",
        "\n",
        "    #print(\"Original Binary Matrix:\\n\", binary_matrix)\n",
        "    print(\"Original binary matix size: \", binary_matrix.shape)\n",
        "#print(\"Filtered Binary Matrix:\\n\", filtered_binary_matrix)\n",
        "    print(\"Filtered binayr matrix size: \", filtered_binary_matrix.shape)\n",
        "\n",
        "    return filtered_binary_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pkh-iq4xQZx"
      },
      "source": [
        "# Signature Vectors (Matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdUd4ngQxZWb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def generate_unique_hash_params(k, prime):\n",
        "\n",
        "    np.random.seed(seed)  # For reproducibility\n",
        "    hash_params = set()\n",
        "\n",
        "    while len(hash_params) < k:\n",
        "        a = np.random.randint(0, prime-1)\n",
        "        d = np.random.randint(1, prime-1)\n",
        "        hash_params.add((a, d))  # Add only unique pairs\n",
        "\n",
        "    #print(\"(a,d) parameters\")\n",
        "    #print(list(hash_params))\n",
        "    return list(hash_params)\n",
        "\n",
        "\n",
        "def hash_function(row, a, d, prime):\n",
        "\n",
        "    return (a + d * row) % prime\n",
        "\n",
        "def minhash_signature_matrix(used_binary_matrix, k, prime):\n",
        "\n",
        "    num_products, num_model_words = used_binary_matrix.shape\n",
        "    print(used_binary_matrix.shape)\n",
        "    w = num_model_words  # Number of rows in the binary matrix\n",
        "    #print(w)\n",
        "    #print(\"num_products\")\n",
        "    #print(num_products)\n",
        "\n",
        "    # Step 1: Generate k random hash functions\n",
        "    permutations = generate_unique_hash_params(k, prime)\n",
        "\n",
        "    # Step 2: Initialize the signature matrix with infinity\n",
        "    signature_matrix = np.full((k, num_products), np.inf)\n",
        "\n",
        "    # Step 3: Compute signature matrix\n",
        "    for row in range(w):\n",
        "        for perm_index, (a, d) in enumerate(permutations):\n",
        "            hash_value = hash_function(row, a, d, prime)\n",
        "            #print(\"hash value:\")\n",
        "            #print(hash_value)\n",
        "            for product_index in range(num_products):\n",
        "                if used_binary_matrix[product_index, row] == 1:  # Only consider rows with 1\n",
        "                    signature_matrix[perm_index, product_index] = min(signature_matrix[perm_index, product_index], hash_value)\n",
        "\n",
        "    return signature_matrix.astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RkbCtJDKkXu"
      },
      "source": [
        "# Check for hash collisions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxJFgOSeKjNS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "def count_collisions(signature_matrix):\n",
        "\n",
        "    total_collisions = 0\n",
        "\n",
        "    # Iterate over each permutation (row in signature matrix)\n",
        "    for perm_index in range(signature_matrix.shape[0]):\n",
        "        # Dictionary to track hash values and their counts\n",
        "        hash_counts = defaultdict(int)\n",
        "\n",
        "        # Iterate over each product (column in signature matrix)\n",
        "        for product_index in range(signature_matrix.shape[1]):\n",
        "            hash_value = signature_matrix[perm_index, product_index]\n",
        "            hash_counts[hash_value] += 1\n",
        "\n",
        "        # Count collisions: if any hash value appears more than once, we have a collision\n",
        "        for count in hash_counts.values():\n",
        "            if count > 1:\n",
        "                # Add the number of collisions for this hash value to the total\n",
        "                total_collisions += count - 1  # Subtract 1 because the first occurrence is not a collision\n",
        "\n",
        "    return total_collisions\n",
        "\n",
        "# Count the collisions in the signature matrix\n",
        "# num_collisions = count_collisions(signature_matrix)\n",
        "# print(f\"Total hash collisions: {num_collisions}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "060MSjlwME4A"
      },
      "source": [
        "# Another check for hash collisions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjoaLCU9MEJA"
      },
      "outputs": [],
      "source": [
        "def analyze_collisions(signature_matrix):\n",
        "    num_collisions = 0\n",
        "    for i in range(signature_matrix.shape[1]):  # Iterate over products\n",
        "        unique_hashes = np.unique(signature_matrix[:, i])\n",
        "        num_collisions += (signature_matrix.shape[0] - len(unique_hashes))\n",
        "    print(f\"Total hash collisions: {num_collisions}\")\n",
        "    return num_collisions\n",
        "# analyze_collisions(signature_matrix)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfwHXcNXgDYO"
      },
      "source": [
        "# **LSH**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZvjFvTREgCbH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "def jaccard_similarity(vec1, vec2):\n",
        "\n",
        "    intersection = np.sum(np.logical_and(vec1, vec2))  # Number of common 1s\n",
        "    union = np.sum(np.logical_or(vec1, vec2))  # Total number of 1s in either vector\n",
        "    return intersection / union if union != 0 else 0\n",
        "\n",
        "\n",
        "def lsh(b, r, given_signature_matrix):\n",
        "\n",
        "    num_hashes, num_products = given_signature_matrix.shape\n",
        "    assert num_hashes == b * r, \"Number of hash functions (k) should be equal to b * r\"\n",
        "\n",
        "    # Step 1: Split the signature matrix into b bands, each with r rows\n",
        "    bands = [given_signature_matrix[i * r:(i + 1) * r] for i in range(b)]\n",
        "\n",
        "    # Step 2: Hash products into buckets per band\n",
        "    candidate_pairs = set()\n",
        "    for band_index in range(b):\n",
        "        band = bands[band_index]\n",
        "        hash_buckets = defaultdict(list)\n",
        "\n",
        "        # For each product, hash the band and assign to a bucket\n",
        "        for product_index in range(num_products):\n",
        "            # Convert the band (vector) into a tuple to hash\n",
        "            band_tuple = tuple(band[:, product_index])  # This is the key for the hash function\n",
        "            bucket_key = hash(band_tuple)  # Create a hash for the tuple\n",
        "\n",
        "            # Store the product in the appropriate bucket\n",
        "            for product_in_bucket in hash_buckets[bucket_key]:\n",
        "                # If two products are in the same bucket, they are candidate pairs\n",
        "                candidate_pairs.add(tuple(sorted([product_index, product_in_bucket])))\n",
        "\n",
        "            # Add the current product to the bucket\n",
        "            hash_buckets[bucket_key].append(product_index)\n",
        "    return candidate_pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwSQ-OfW79G3"
      },
      "source": [
        "# True pairs (duplicates)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwbmBbuE_iho"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations\n",
        "from collections import defaultdict\n",
        "\n",
        "def get_true_pairs_from_list(data_id):\n",
        "\n",
        "    # Step 1: Group products by modelID\n",
        "    model_groups = defaultdict(list)\n",
        "    for index, product in enumerate(data_id):\n",
        "        modelID = product['modelID']\n",
        "        model_groups[modelID].append(index)\n",
        "\n",
        "    # Step 2: Generate pairs within each group\n",
        "    true_pairs = []\n",
        "    for modelID, product_indices in model_groups.items():\n",
        "        true_pairs.extend(combinations(product_indices, 2))\n",
        "\n",
        "    return true_pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KT2zPSZI6N4"
      },
      "source": [
        "# From Pairs to Unique Duplicates found (Not used)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npP6U9l7I_EZ"
      },
      "outputs": [],
      "source": [
        "def get_duplicates_from_pairs(pairs_of_duplicates):\n",
        "  # Step 3: Find unique duplicates\n",
        "    # Create a set of all unique product indices involved in duplicates\n",
        "    found_unique_duplicates = set()\n",
        "    for pair in pairs_of_duplicates:\n",
        "        found_unique_duplicates.update(pair)\n",
        "\n",
        "    # The total number of unique products involved in duplicates\n",
        "    number_duplicates = len(found_unique_duplicates)\n",
        "\n",
        "    return (number_duplicates, found_unique_duplicates)\n",
        "\n",
        "# number_true_unique_duplicates, true_unique_duplicates = get_duplicates_from_pairs(true_pairs)\n",
        "\n",
        "# print(number_true_unique_duplicates)\n",
        "# print(true_unique_duplicates)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H88Lu3K5411X"
      },
      "source": [
        "# Hierarchical Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qnnRD2y463n"
      },
      "outputs": [],
      "source": [
        "from scipy.cluster.hierarchy import linkage, fcluster\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "import numpy as np\n",
        "\n",
        "def hierarchical_clustering(data, used_binary_matrix, b, r, given_signature_matrix, used_method):\n",
        "\n",
        "    threshold = (1 / b) ** (1 / r)\n",
        "\n",
        "    # Step 1: Use LSH to get candidate pairs\n",
        "    candidate_pairs = lsh(b, r, given_signature_matrix)\n",
        "    print(candidate_pairs)\n",
        "    print(len(candidate_pairs))\n",
        "\n",
        "    # Step 2: Filter based on brand\n",
        "    filtered_pairs = []\n",
        "    for p1, p2 in candidate_pairs:\n",
        "        brand1 = data[p1]['featuresMap'].get('Brand', '').lower()\n",
        "        brand2 = data[p2]['featuresMap'].get('Brand', '').lower()\n",
        "        if brand1 == brand2 or brand1 == '' or brand2 == '':\n",
        "            filtered_pairs.append((p1, p2))\n",
        "    print(len(filtered_pairs))\n",
        "\n",
        "    # Step 3: Filter based on shop\n",
        "    filtered_pairs_2 = []\n",
        "    for prod1, prod2 in filtered_pairs:\n",
        "        shop1 = data[prod1].get('shop', '').lower()\n",
        "        shop2 = data[prod2].get('shop', '').lower()\n",
        "        if shop1 != shop2:\n",
        "            filtered_pairs_2.append((prod1, prod2))\n",
        "    print(len(filtered_pairs_2))\n",
        "    #number_comparisons_clusters = len(filtered_pairs_2)\n",
        "\n",
        "    # Step 4: Compute similarity matrix for candidate products\n",
        "    product_indices = set(prod for pair in filtered_pairs_2 for prod in pair)\n",
        "    product_indices = sorted(product_indices)  # Ensure consistent ordering\n",
        "    index_to_product = {i: product for i, product in enumerate(product_indices)}\n",
        "    product_to_index = {product: i for i, product in enumerate(product_indices)}\n",
        "\n",
        "    num_products = len(product_indices)\n",
        "    similarity_matrix = np.zeros((num_products, num_products))\n",
        "\n",
        "    for i in range(num_products):\n",
        "        for j in range(i + 1, num_products):\n",
        "            prod1 = index_to_product[i]\n",
        "            prod2 = index_to_product[j]\n",
        "            similarity = jaccard_similarity(used_binary_matrix[prod1, :], used_binary_matrix[prod2, :])\n",
        "            #print(prod1, prod2)\n",
        "            #print(similarity)\n",
        "            similarity_matrix[i, j] = similarity\n",
        "            similarity_matrix[j, i] = similarity  # Symmetric matrix\n",
        "\n",
        "    # Check if the similarity matrix is empty\n",
        "    if similarity_matrix.size == 0:\n",
        "        return []  # Return an empty result without any message\n",
        "\n",
        "    # Step 5: Perform hierarchical clustering\n",
        "    # Convert similarity matrix to a distance matrix\n",
        "    distance_matrix = 1 - similarity_matrix\n",
        "    #print(similarity_matrix)\n",
        "    print(similarity_matrix.shape)\n",
        "    #print(distance_matrix)\n",
        "    # Ensure the diagonal of the distance matrix is zero\n",
        "    np.fill_diagonal(distance_matrix, 0)\n",
        "    condensed_distance_matrix = squareform(distance_matrix)  # Convert to condensed form\n",
        "    linkage_matrix = linkage(condensed_distance_matrix, method=used_method) # 'average' 'complete' 'single'\n",
        "\n",
        "    # Step 6: Form clusters based on threshold\n",
        "    # The threshold is on the distance, so we use (1 - threshold) as the cutoff\n",
        "    clusters = fcluster(linkage_matrix, t = 1 - threshold, criterion='distance')\n",
        "\n",
        "    # Step 7: Group products into clusters\n",
        "    cluster_dict = {}\n",
        "    for product_index, cluster_id in zip(product_indices, clusters):\n",
        "        if cluster_id not in cluster_dict:\n",
        "            cluster_dict[cluster_id] = []\n",
        "        cluster_dict[cluster_id].append(product_index)\n",
        "\n",
        "    # Only keep clusters with more than one product as valid duplicates\n",
        "    valid_clusters = [cluster for cluster in cluster_dict.values() if len(cluster) > 1]\n",
        "\n",
        "    return valid_clusters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCkLAgCDoxyW"
      },
      "source": [
        "# Get pairs from clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7la3p_x-ozwi"
      },
      "outputs": [],
      "source": [
        "from itertools import combinations\n",
        "\n",
        "def get_pairs_from_clusters(clusters):\n",
        "    pairs = []\n",
        "\n",
        "    for cluster in clusters:\n",
        "        # Generate all possible pairs from the cluster\n",
        "        cluster_pairs = combinations(cluster, 2)\n",
        "        # Append the pairs to the list\n",
        "        pairs.extend(cluster_pairs)\n",
        "\n",
        "    return pairs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tARqhV00wobj"
      },
      "source": [
        "# Post Cluster Filtering (Not used)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9OuqPyYwr0-"
      },
      "outputs": [],
      "source": [
        "def extra_filter_cluster(b,r, given_pairs):\n",
        "\n",
        "    # Filter based on brand : different brand - no pair\n",
        "    filtered_pairs = []\n",
        "    for p1, p2 in given_pairs: # get_pairs_from_clusters(clusters)\n",
        "        #print(p1)\n",
        "        #print(len(data))\n",
        "        # Get brand of the products, handle the case where 'Brand' key is missing\n",
        "        brand1 = data[p1]['featuresMap'].get('Brand', '').lower()\n",
        "        #print(brand1)\n",
        "        brand2 = data[p2]['featuresMap'].get('Brand', '').lower()  # Default to empty string if 'Brand' key is missing\n",
        "        #print(brand2)\n",
        "\n",
        "        if brand1 == brand2 or brand1 == '' or brand2 == '':  # Consider missing brands as the same\n",
        "            # Only consider pairs with the same brand or where one of the products has no brand\n",
        "            filtered_pairs.append((p1, p2))\n",
        "    print(len(filtered_pairs))\n",
        "\n",
        "    # Filter based on shop : same shop - no pair\n",
        "    filtered_pairs_2 = []\n",
        "    for prod1, prod2 in filtered_pairs:\n",
        "        #print(prod1)\n",
        "        # Get brand of the products, handle the case where 'Brand' key is missing\n",
        "        shop1 = data[prod1].get('shop', '').lower()\n",
        "        #print(shop1)\n",
        "        shop2 = data[prod2].get('shop', '').lower()  # Default to empty string if 'Brand' key is missing\n",
        "        #print(shop2)\n",
        "\n",
        "        if shop1  != shop2:  # Consider missing brands as the same\n",
        "            # Only consider pairs with the same brand or where one of the products has no brand\n",
        "            filtered_pairs_2.append((prod1, prod2))\n",
        "\n",
        "    print(len(filtered_pairs_2))\n",
        "    return filtered_pairs_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CITbH7zf5myZ"
      },
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m_YvD1au5vZ9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "def bootstrap(data, data_id, n_bootstraps):\n",
        "\n",
        "    train_sets = []\n",
        "    test_sets = []\n",
        "    train_id_sets = []\n",
        "    test_id_sets = []\n",
        "    number_products_test = []\n",
        "    number_products_train = []\n",
        "    n = len(data)\n",
        "\n",
        "    for _ in range(n_bootstraps):\n",
        "        # Number of unique samples for bootstrapping (~63% of the data)\n",
        "        train_size = int(n * 0.63)\n",
        "\n",
        "        # Sample 63% unique indices from the original data (no replacement)\n",
        "        train_indices = np.random.choice(n, size=train_size, replace=False)\n",
        "\n",
        "        # The remaining indices form the test set (the out-of-sample data)\n",
        "        test_indices = [i for i in range(n) if i not in train_indices]\n",
        "\n",
        "        # Sample the remaining 37% from the unique indices (with replacement)\n",
        "        #remaining_indices = np.random.choice(unique_train_indices, size=n - train_size, replace=True)\n",
        "\n",
        "        # Combine unique and remaining indices to form the bootstrapped dataset (total size = n)\n",
        "        #train_indices = list(unique_train_indices) #+ list(remaining_indices)\n",
        "\n",
        "        # Store the number of products in the test set\n",
        "        number_products_test.append(len(test_indices))\n",
        "        number_products_train.append(len(train_indices))\n",
        "\n",
        "        ################### data sets for clean data\n",
        "        # Create the training and test sets based on indices\n",
        "        train_set = [data[i] for i in train_indices]\n",
        "        test_set = [data[i] for i in test_indices]\n",
        "\n",
        "        # Append to the respective lists\n",
        "        train_sets.append(train_set)\n",
        "        test_sets.append(test_set)\n",
        "\n",
        "        ################### data sets with still model ID info\n",
        "        # Create the training and test sets based on indices\n",
        "        train_id_set = [data_id[i] for i in train_indices]\n",
        "        test_id_set = [data_id[i] for i in test_indices]\n",
        "\n",
        "        # Append to the respective lists\n",
        "        train_id_sets.append(train_id_set)\n",
        "        test_id_sets.append(test_id_set)\n",
        "\n",
        "    return train_sets, test_sets, train_id_sets, test_id_sets, number_products_train, number_products_test\n",
        "\n",
        "def evaluate_performance(used_pred_pairs_lsh, used_pred_pairs_clusters, used_true_pairs, used_current_possible_pairs): # for test data\n",
        "\n",
        "    # Calculate TP, FP, TN, FN\n",
        "    # For Clusters\n",
        "    TP = len(set(used_pred_pairs_clusters).intersection(used_true_pairs))\n",
        "    print(\"true positives\", TP)\n",
        "    FP = len(used_pred_pairs_clusters) - TP # is non-duplicate, but predicted as duplicates\n",
        "    print(\"false positives\", FP)\n",
        "    FN = len(used_true_pairs) - TP # it's duplicate, but is predicted as non-duplicate\n",
        "    print(\"false negatives\", FN,  \"too many FN?\")\n",
        "    TN = used_current_possible_pairs - len(used_pred_pairs_clusters) - len(used_true_pairs) # NOT in the pred_pairs (in the ^pred_pairs), and NOT in true_pairs (in the ^true_pairs)\n",
        "    print(\"true negatives\", TN)\n",
        "\n",
        "    # Calculate F1-measure for Clusters\n",
        "    precision = TP / (TP + FP) if TP + FP != 0 else 0\n",
        "    recall = TP / (TP + FN) if TP + FN != 0 else 0\n",
        "    f1_measure = 2 * (precision * recall) / (precision + recall) if precision + recall != 0 else 0\n",
        "\n",
        "    # Calculate Pair Quality and Pair Completeness, F1* for LSH\n",
        "    number_comparisons = len(used_pred_pairs_lsh) # number of candidate pairs given by LSH, for test data\n",
        "    print(\"number comparisons, should equal number test_candidate_pairs (lsh) \", number_comparisons)\n",
        "\n",
        "    pair_quality = TP / number_comparisons if number_comparisons > 0 else 0 # number_comparisons = len(test_candidate_pairs) = len(test_pred_pairs_lsh)\n",
        "    total_duplicates = len(used_true_pairs) # number of real duplicates in the whole test data\n",
        "    pair_completeness = TP / total_duplicates if total_duplicates > 0 else 0\n",
        "    f1_star = 2 * (pair_quality * pair_completeness) / (pair_quality + pair_completeness) if pair_quality + pair_completeness != 0 else 0\n",
        "\n",
        "    return f1_measure, pair_quality, pair_completeness, f1_star"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zb3SSyGnaDr"
      },
      "source": [
        "# Main run (Initialise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D50rY2jvxHju"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from collections import Counter\n",
        "import random\n",
        "from sympy import nextprime\n",
        "from collections import defaultdict\n",
        "from itertools import combinations\n",
        "from scipy.cluster.hierarchy import linkage, fcluster\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "\n",
        "seed = 987654\n",
        "np.random.seed(seed)\n",
        "\n",
        "#all_possible_pairs = (1624 * 1623) / 2\n",
        "\n",
        "data_path = '/content/drive/.../TVs-all-merged.json'\n",
        "with open(data_path, 'r') as file:\n",
        "    data_json = json.load(file)\n",
        "#print(data_json)\n",
        "print(len(data_json))\n",
        "\n",
        "# To store the individual products\n",
        "product_list = []\n",
        "\n",
        "# Iterate through the data to process each product under the same model ID\n",
        "for model_id, products in data_json.items():\n",
        "    for product in products:\n",
        "        # Add each product to the product_list, preserving all the information\n",
        "        product_list.append(product)\n",
        "\n",
        "# Print the individual products\n",
        "print(\"Total number of products:\", len(product_list))\n",
        "#for product in product_list:\n",
        " #   print(product)\n",
        "\n",
        "data_id = product_list # Data still including modelID\n",
        "#print(len(data_id))\n",
        "#print(data_id)\n",
        "#print(data_json)\n",
        "\n",
        "# Select the first x products from your data\n",
        "#data_id = data_id[:800] #!!!!!!!!!!\n",
        "\n",
        "# Separate modelID from the rest, as modelID FOR EVALUATION ONLY, not testing\n",
        "training_data = []  # For the training set (excluding modelID)\n",
        "evaluation_data = {}  # For the testing/evaluation (modelID mapping)\n",
        "\n",
        "# Iterate through the dataset to process each product in the list\n",
        "for entry in data_id:\n",
        "    # Store the modelID for evaluation\n",
        "    model_id = entry.get(\"modelID\")\n",
        "    if model_id not in evaluation_data:\n",
        "        evaluation_data[model_id] = []\n",
        "    evaluation_data[model_id].append(entry)  # Append entry for evaluation purposes\n",
        "\n",
        "    # Prepare training data by excluding modelID\n",
        "    training_entry = entry.copy()\n",
        "    training_entry.pop(\"modelID\", None)\n",
        "    training_data.append(training_entry)\n",
        "\n",
        "#print(\"Training Data:\")\n",
        "#print(training_data)\n",
        "# Count the number of products in training_data\n",
        "product_count = len(training_data)\n",
        "\n",
        "print(f\"Number of products in training_data: {product_count}\")\n",
        "\n",
        "data = training_data  # Data with modelID excluded\n",
        "\n",
        "############################################################\n",
        "# true_pairs = get_true_pairs_from_list(data_id)\n",
        "# print(\"True Pairs:\", true_pairs)\n",
        "# print(\"Number True Pairs:\", len(true_pairs))\n",
        "\n",
        "n_bootstraps = 5 #5\n",
        "# List of b values to iterate over\n",
        "train_b_values = [1, 2, 3, 5, 6, 10, 15, 17, 30, 34, 51, 85, 102, 170, 255, 510]\n",
        "number_b_train = len(train_b_values)\n",
        "\n",
        "test_b_values = [1, 2, 3, 4, 5, 6, 9, 10, 12, 15, 18, 20, 25, 30, 36, 45, 50, 60, 75, 90, 100, 150, 180, 225, 300, 450, 900]\n",
        "number_b_test = len(test_b_values)\n",
        "\n",
        "# Create a data structure to hold results: a 2D list of dictionaries\n",
        "# Rows correspond to b values, columns correspond to bootstraps\n",
        "single_train_results_matrix = [[{\"f1_measures\": [], \"f1_stars\": [], \"pair_qualities\": [], \"pair_completenesses\": [], \"fraction_of_comparisons\": []}\n",
        "                   for _ in range(n_bootstraps)] for _ in range(number_b_train)]\n",
        "\n",
        "average_train_results_matrix = [[{\"f1_measures\": [], \"f1_stars\": [], \"pair_qualities\": [], \"pair_completenesses\": [], \"fraction_of_comparisons\": []}\n",
        "                   for _ in range(n_bootstraps)] for _ in range(number_b_train)]\n",
        "\n",
        "complete_train_results_matrix = [[{\"f1_measures\": [], \"f1_stars\": [], \"pair_qualities\": [], \"pair_completenesses\": [], \"fraction_of_comparisons\": []}\n",
        "                   for _ in range(n_bootstraps)] for _ in range(number_b_train)]\n",
        "\n",
        "test_results_matrix = [[{\"f1_measures\": [], \"f1_stars\": [], \"pair_qualities\": [], \"pair_completenesses\": [], \"fraction_of_comparisons\": []}\n",
        "                   for _ in range(n_bootstraps)] for _ in range(number_b_test)]\n",
        "\n",
        "\n",
        "\n",
        "train_data_sets, test_data_sets, id_train_data_sets, id_test_data_sets, train_number_of_products, test_number_of_products = bootstrap(data, data_id, n_bootstraps)\n",
        "print(\"train data sets \", train_data_sets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixN3AO7cyGVZ"
      },
      "source": [
        "# Main Run (Train Data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-V11dF-eneL_"
      },
      "outputs": [],
      "source": [
        "############### DO FOR TRAIN DATA FIRST:   ################\n",
        "###########################################################\n",
        "# do model words, binary, signature, lsh: on train data, with train_k and train_b, train_r => train_threshold : SAME FOR ALL CLUSTERING OPTIONS - RUN ONLY ONCE FOR TRAIN\n",
        "# do clustering 3 options: single (average, complete) => get average performance measures over bootstraps for option 1 - all for TRAIN (inc. fraction of comparisons)\n",
        "# do for options 2, 3 - record all 3 results - don't overwrite\n",
        "# select the 'method' based on the best performance: higher PQ, higher PC, higher F1*\n",
        "\n",
        "for bootstrap_index, train_data in enumerate(train_data_sets):\n",
        "    # Get the corresponding test data and number of products for this bootstrap\n",
        "    #current_test_data = test_data_sets[bootstrap_index]\n",
        "    current_train_data = train_data_sets[bootstrap_index]\n",
        "    #print(\"current train data \", current_train_data)\n",
        "    current_train_number_unique_products = train_number_of_products[bootstrap_index]\n",
        "    #current_test_number_unique_products = test_number_of_products[bootstrap_index]\n",
        "\n",
        "    current_id_train_data_sets = id_train_data_sets[bootstrap_index] # data_id for train data\n",
        "    #current_id_test_data_sets = id_test_data_sets[bootstrap_index] # data_id for test data\n",
        "\n",
        "    train_true_pairs = get_true_pairs_from_list(current_id_train_data_sets)\n",
        "    #test_true_pairs = get_true_pairs_from_list(current_id_test_data_sets)\n",
        "    #print(\"Train true Pairs:\", train_true_pairs)\n",
        "    #print(\"Number Train True Pairs:\", len(train_true_pairs))\n",
        "    # print(\"Test true Pairs:\", test_true_pairs)\n",
        "    # print(\"Number Test True Pairs:\", len(test_true_pairs))\n",
        "\n",
        "    # Print the current number of unique products in the used data\n",
        "    #print(\"current_train_number_unique_products:\", current_train_number_unique_products)\n",
        "\n",
        "    # Calculate the number of possible pairs for the used data\n",
        "    current_possible_pairs = current_train_number_unique_products * (current_train_number_unique_products - 1) // 2\n",
        "    #print(\"current_possible_pairs:\", current_possible_pairs)\n",
        "\n",
        "\n",
        "    ####################################################################################\n",
        "    #train_model_words_data_novel = extract_model_words_novel(current_train_data) #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! change type model words\n",
        "    train_model_words_data_novel_BOTH = extract_model_words_novel_BOTH(current_train_data)\n",
        "    #train_model_words_data_original = extract_model_words_original_BOTH(current_train_data)\n",
        "\n",
        "    train_binary_matrix, train_model_words_list = get_binary_matrix(current_train_data, train_model_words_data_novel_BOTH) ######################################################################\n",
        "    #train_binary_matrix, train_model_words_list = get_binary_matrix_with_brand_influence(current_train_data, train_model_words_data_novel_BOTH, 1, current_id_train_data_sets)\n",
        "\n",
        "    #train_binary_matrix = filter_binary_matrix(train_binary_matrix) ################################################################################################################\n",
        "\n",
        "    train_num_model_words = train_binary_matrix.shape[1]\n",
        "    print(\"train num_model_words\")\n",
        "    print(train_num_model_words, len(train_model_words_list))\n",
        "\n",
        "    # k_test = 112 #num_model_words // 2  # Size of signature vector is half the binary vector size !! change here\n",
        "    k_train = 510\n",
        "\n",
        "    prime_train = nextprime(3*train_num_model_words)\n",
        "    print(\"prime train:\")\n",
        "    print(prime_train)\n",
        "\n",
        "    train_signature_matrix = minhash_signature_matrix(train_binary_matrix, k_train, prime_train)  # FILTERED OR BINARY!!!!!!!!!!!!!!!! change also here\n",
        "    #print(\"Train Signature Matrix:\")\n",
        "    #print(train_signature_matrix)\n",
        "    #print(\"Train Sginature matrix sizes: \", train_signature_matrix.shape)\n",
        "\n",
        "    for b_index, b in enumerate(train_b_values):\n",
        "\n",
        "        # Calculate r and the corresponding threshold\n",
        "        r_train = k_train // b\n",
        "        threshold = (1 / b) ** (1 / r_train)\n",
        "        print(f\"b: {b}, r: {r_train}, threshold: {threshold}\")\n",
        "\n",
        "        # Perform LSH to find candidate pairs\n",
        "        train_candidate_pairs = lsh(b, r_train, train_signature_matrix)\n",
        "        #print(f\"Candidate pairs: {candidate_pairs}\")\n",
        "        print(f\"Number train candidate pairs: {len(train_candidate_pairs)}\")\n",
        "\n",
        "        number_comparisons = len(train_candidate_pairs) # for test ONLY\n",
        "        fraction_of_comparisons = number_comparisons/current_possible_pairs # for teset ONLY\n",
        "        print(\"Number of comparisons:\", number_comparisons)\n",
        "\n",
        "        fraction_of_comparisons = number_comparisons/current_possible_pairs\n",
        "\n",
        "        # Perform hierarchical clustering\n",
        "        clusters_single = hierarchical_clustering(current_train_data, train_binary_matrix, b, r_train, train_signature_matrix, 'single')\n",
        "        clusters_average = hierarchical_clustering(current_train_data, train_binary_matrix, b, r_train, train_signature_matrix, 'average')\n",
        "        clusters_complete = hierarchical_clustering(current_train_data, train_binary_matrix, b, r_train, train_signature_matrix, 'complete')\n",
        "        # print(\"Clusters of duplicates:\")\n",
        "        # for cluster in clusters:\n",
        "        #     print(cluster)\n",
        "\n",
        "        # Get pairs from clusters\n",
        "        single_cluster_pairs = get_pairs_from_clusters(clusters_single)\n",
        "        average_cluster_pairs = get_pairs_from_clusters(clusters_average)\n",
        "        complete_cluster_pairs = get_pairs_from_clusters(clusters_complete)\n",
        "\n",
        "        # Evaluate performance\n",
        "        single_f1_measure, single_pair_quality, single_pair_completeness, single_f1_star = evaluate_performance(train_candidate_pairs, single_cluster_pairs, train_true_pairs, current_possible_pairs)\n",
        "        average_f1_measure, average_pair_quality, average_pair_completeness, average_f1_star = evaluate_performance(train_candidate_pairs, average_cluster_pairs, train_true_pairs, current_possible_pairs)\n",
        "        complete_f1_measure, complete_pair_quality, complete_pair_completeness, complete_f1_star = evaluate_performance(train_candidate_pairs, complete_cluster_pairs, train_true_pairs, current_possible_pairs)\n",
        "\n",
        "        # Store the performance metrics for this bootstrap and this b value\n",
        "        # Store the performance metrics in the corresponding matrix entry\n",
        "        single_train_results_matrix[b_index][bootstrap_index][\"f1_measures\"].append(single_f1_measure)\n",
        "        single_train_results_matrix[b_index][bootstrap_index][\"f1_stars\"].append(single_f1_star)\n",
        "        single_train_results_matrix[b_index][bootstrap_index][\"pair_qualities\"].append(single_pair_quality)\n",
        "        single_train_results_matrix[b_index][bootstrap_index][\"pair_completenesses\"].append(single_pair_completeness)\n",
        "\n",
        "        single_train_results_matrix[b_index][bootstrap_index][\"fraction_of_comparisons\"] = fraction_of_comparisons\n",
        "\n",
        "        average_train_results_matrix[b_index][bootstrap_index][\"f1_measures\"].append(average_f1_measure)\n",
        "        average_train_results_matrix[b_index][bootstrap_index][\"f1_stars\"].append(average_f1_star)\n",
        "        average_train_results_matrix[b_index][bootstrap_index][\"pair_qualities\"].append(average_pair_quality)\n",
        "        average_train_results_matrix[b_index][bootstrap_index][\"pair_completenesses\"].append(average_pair_completeness)\n",
        "\n",
        "        average_train_results_matrix[b_index][bootstrap_index][\"fraction_of_comparisons\"] = fraction_of_comparisons\n",
        "\n",
        "        complete_train_results_matrix[b_index][bootstrap_index][\"f1_measures\"].append(complete_f1_measure)\n",
        "        complete_train_results_matrix[b_index][bootstrap_index][\"f1_stars\"].append(complete_f1_star)\n",
        "        complete_train_results_matrix[b_index][bootstrap_index][\"pair_qualities\"].append(complete_pair_quality)\n",
        "        complete_train_results_matrix[b_index][bootstrap_index][\"pair_completenesses\"].append(complete_pair_completeness)\n",
        "\n",
        "        complete_train_results_matrix[b_index][bootstrap_index][\"fraction_of_comparisons\"] = fraction_of_comparisons\n",
        "\n",
        "        #print(\"results matrix \", results_matrix)\n",
        "        #print(\"RESULTS MATRIX SIZE, AFTER EACH B\", len(results_matrix))\n",
        "\n",
        "# Calculate the average results across bootstraps for each b\n",
        "single_final_results = []\n",
        "for b_index, b in enumerate(train_b_values):\n",
        "    avg_f1_measure = np.mean([np.mean(single_train_results_matrix[b_index][bootstrap][\"f1_measures\"]) for bootstrap in range(n_bootstraps)])\n",
        "    avg_f1_star = np.mean([np.mean(single_train_results_matrix[b_index][bootstrap][\"f1_stars\"]) for bootstrap in range(n_bootstraps)])\n",
        "    avg_pair_quality = np.mean([np.mean(single_train_results_matrix[b_index][bootstrap][\"pair_qualities\"]) for bootstrap in range(n_bootstraps)])\n",
        "    avg_pair_completeness = np.mean([np.mean(single_train_results_matrix[b_index][bootstrap][\"pair_completenesses\"]) for bootstrap in range(n_bootstraps)])\n",
        "    avg_fraction_of_comparisons = np.mean([single_train_results_matrix[b_index][bootstrap][\"fraction_of_comparisons\"] for bootstrap in range(n_bootstraps)])\n",
        "    #print(\"for this b, we  get this avg g1 star \", b, avg_f1_star)\n",
        "\n",
        "    # Store the averaged results for the current b\n",
        "    single_final_results.append({\n",
        "        \"b\": b,\n",
        "        \"avg_f1_measure\": avg_f1_measure,\n",
        "        \"avg_f1_star\": avg_f1_star,\n",
        "        \"avg_pair_quality\": avg_pair_quality,\n",
        "        \"avg_pair_completeness\": avg_pair_completeness,\n",
        "        \"fraction_of_comparisons\": avg_fraction_of_comparisons,\n",
        "    })\n",
        "\n",
        "average_final_results = []\n",
        "for b_index, b in enumerate(train_b_values):\n",
        "    avg_f1_measure = np.mean([np.mean(average_train_results_matrix[b_index][bootstrap][\"f1_measures\"]) for bootstrap in range(n_bootstraps)])\n",
        "    avg_f1_star = np.mean([np.mean(average_train_results_matrix[b_index][bootstrap][\"f1_stars\"]) for bootstrap in range(n_bootstraps)])\n",
        "    avg_pair_quality = np.mean([np.mean(average_train_results_matrix[b_index][bootstrap][\"pair_qualities\"]) for bootstrap in range(n_bootstraps)])\n",
        "    avg_pair_completeness = np.mean([np.mean(average_train_results_matrix[b_index][bootstrap][\"pair_completenesses\"]) for bootstrap in range(n_bootstraps)])\n",
        "    avg_fraction_of_comparisons = np.mean([average_train_results_matrix[b_index][bootstrap][\"fraction_of_comparisons\"] for bootstrap in range(n_bootstraps)])\n",
        "    #print(\"for this b, we  get this avg g1 star \", b, avg_f1_star)\n",
        "\n",
        "    # Store the averaged results for the current b\n",
        "    average_final_results.append({\n",
        "        \"b\": b,\n",
        "        \"avg_f1_measure\": avg_f1_measure,\n",
        "        \"avg_f1_star\": avg_f1_star,\n",
        "        \"avg_pair_quality\": avg_pair_quality,\n",
        "        \"avg_pair_completeness\": avg_pair_completeness,\n",
        "        \"fraction_of_comparisons\": avg_fraction_of_comparisons,\n",
        "    })\n",
        "\n",
        "complete_final_results = []\n",
        "for b_index, b in enumerate(train_b_values):\n",
        "    avg_f1_measure = np.mean([np.mean(complete_train_results_matrix[b_index][bootstrap][\"f1_measures\"]) for bootstrap in range(n_bootstraps)])\n",
        "    avg_f1_star = np.mean([np.mean(complete_train_results_matrix[b_index][bootstrap][\"f1_stars\"]) for bootstrap in range(n_bootstraps)])\n",
        "    avg_pair_quality = np.mean([np.mean(complete_train_results_matrix[b_index][bootstrap][\"pair_qualities\"]) for bootstrap in range(n_bootstraps)])\n",
        "    avg_pair_completeness = np.mean([np.mean(complete_train_results_matrix[b_index][bootstrap][\"pair_completenesses\"]) for bootstrap in range(n_bootstraps)])\n",
        "    avg_fraction_of_comparisons = np.mean([complete_train_results_matrix[b_index][bootstrap][\"fraction_of_comparisons\"] for bootstrap in range(n_bootstraps)])\n",
        "    #print(\"for this b, we  get this avg g1 star \", b, avg_f1_star)\n",
        "\n",
        "    # Store the averaged results for the current b\n",
        "    complete_final_results.append({\n",
        "        \"b\": b,\n",
        "        \"avg_f1_measure\": avg_f1_measure,\n",
        "        \"avg_f1_star\": avg_f1_star,\n",
        "        \"avg_pair_quality\": avg_pair_quality,\n",
        "        \"avg_pair_completeness\": avg_pair_completeness,\n",
        "        \"fraction_of_comparisons\": avg_fraction_of_comparisons,\n",
        "    })\n",
        "\n",
        "\n",
        "\n",
        "print(\"Single \", single_final_results)\n",
        "print(\"Average \", average_final_results)\n",
        "print(\"Complete \", complete_final_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7WVTebiuKTOr"
      },
      "source": [
        "# Up Main Main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk1Nb-yysRph"
      },
      "source": [
        "# Comparison Train Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAuWYGFMlyEe"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Convert the results of each linkage method to DataFrames\n",
        "average_results_df = pd.DataFrame(average_final_results)\n",
        "complete_results_df = pd.DataFrame(complete_final_results)\n",
        "single_results_df = pd.DataFrame(single_final_results)\n",
        "\n",
        "# Generate Graphs\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Graph 1: Fraction of Comparisons vs Average F1 Measure\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(average_results_df['fraction_of_comparisons'], average_results_df['avg_f1_measure'], marker='o', label='Average Linkage')\n",
        "plt.plot(complete_results_df['fraction_of_comparisons'], complete_results_df['avg_f1_measure'], marker='o', label='Complete Linkage')\n",
        "plt.plot(single_results_df['fraction_of_comparisons'], single_results_df['avg_f1_measure'], marker='o', label='Single Linkage')\n",
        "plt.xlabel('Fraction of Comparisons')\n",
        "plt.ylabel('Average F1 Measure')\n",
        "plt.title('Fraction of Comparisons vs F1 Measure')\n",
        "plt.legend()\n",
        "\n",
        "# Graph 2: Fraction of Comparisons vs Average F1* Measure\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(average_results_df['fraction_of_comparisons'], average_results_df['avg_f1_star'], marker='o', label='Average Linkage')\n",
        "plt.plot(complete_results_df['fraction_of_comparisons'], complete_results_df['avg_f1_star'], marker='o', label='Complete Linkage')\n",
        "plt.plot(single_results_df['fraction_of_comparisons'], single_results_df['avg_f1_star'], marker='o', label='Single Linkage')\n",
        "plt.xlabel('Fraction of Comparisons')\n",
        "plt.ylabel('Average F1* Measure')\n",
        "plt.title('Fraction of Comparisons vs F1* Measure')\n",
        "plt.legend()\n",
        "\n",
        "# Graph 3: Fraction of Comparisons vs Average Pair Quality\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(average_results_df['fraction_of_comparisons'], average_results_df['avg_pair_quality'], marker='o', label='Average Linkage')\n",
        "plt.plot(complete_results_df['fraction_of_comparisons'], complete_results_df['avg_pair_quality'], marker='o', label='Complete Linkage')\n",
        "plt.plot(single_results_df['fraction_of_comparisons'], single_results_df['avg_pair_quality'], marker='o', label='Single Linkage')\n",
        "plt.xlabel('Fraction of Comparisons')\n",
        "plt.ylabel('Average Pair Quality')\n",
        "plt.title('Fraction of Comparisons vs Pair Quality')\n",
        "plt.legend()\n",
        "\n",
        "# Graph 4: Fraction of Comparisons vs Average Pair Completeness\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(average_results_df['fraction_of_comparisons'], average_results_df['avg_pair_completeness'], marker='o', label='Average Linkage')\n",
        "plt.plot(complete_results_df['fraction_of_comparisons'], complete_results_df['avg_pair_completeness'], marker='o', label='Complete Linkage')\n",
        "plt.plot(single_results_df['fraction_of_comparisons'], single_results_df['avg_pair_completeness'], marker='o', label='Single Linkage')\n",
        "plt.xlabel('Fraction of Comparisons')\n",
        "plt.ylabel('Average Pair Completeness')\n",
        "plt.title('Fraction of Comparisons vs Pair Completeness')\n",
        "plt.legend()\n",
        "\n",
        "# Graph 5: Fraction of Comparisons vs Average F1 Measure & F1* Measure\n",
        "# plt.subplot(2, 3, 5)\n",
        "# plt.plot(average_results_df['fraction_of_comparisons'], average_results_df['avg_f1_measure'], marker='o', label='Average F1 Measure (Average Linkage)')\n",
        "# plt.plot(complete_results_df['fraction_of_comparisons'], complete_results_df['avg_f1_measure'], marker='o', label='Average F1 Measure (Complete Linkage)')\n",
        "# plt.plot(single_results_df['fraction_of_comparisons'], single_results_df['avg_f1_measure'], marker='o', label='Average F1 Measure (Single Linkage)', linestyle='--')\n",
        "\n",
        "# plt.plot(average_results_df['fraction_of_comparisons'], average_results_df['avg_f1_star'], marker='o', label='F1* Measure (Average Linkage)', linestyle=':')\n",
        "# plt.plot(complete_results_df['fraction_of_comparisons'], complete_results_df['avg_f1_star'], marker='o', label='F1* Measure (Complete Linkage)', linestyle=':')\n",
        "# plt.plot(single_results_df['fraction_of_comparisons'], single_results_df['avg_f1_star'], marker='o', label='F1* Measure (Single Linkage)', linestyle=':')\n",
        "\n",
        "# plt.xlabel('Fraction of Comparisons')\n",
        "# plt.ylabel('F1 Measures')\n",
        "# plt.title('Fraction of Comparisons vs F1 & F1* Measures')\n",
        "# plt.legend()\n",
        "\n",
        "# Adjust layout and show\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysABYyOxlkN_"
      },
      "source": [
        "# Main Run (Test Data)\n",
        "## Run on the Test data based on the chosen best 'method' (single vs average vs complete) -> 'single'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UYbNeMfzkkw"
      },
      "outputs": [],
      "source": [
        "for bootstrap_index, test_data in enumerate(test_data_sets):\n",
        "    # Get the corresponding test data and number of products for this bootstrap\n",
        "    current_test_data = test_data_sets[bootstrap_index]\n",
        "    #print(\"current test data \", current_test_data)\n",
        "    current_test_number_unique_products = test_number_of_products[bootstrap_index]\n",
        "\n",
        "    current_id_test_data_sets = id_test_data_sets[bootstrap_index] # data_id for test data\n",
        "\n",
        "    test_true_pairs = get_true_pairs_from_list(current_id_test_data_sets)\n",
        "\n",
        "    #print(\"test true Pairs:\", test_true_pairs)\n",
        "    print(\"Number test True Pairs:\", len(test_true_pairs))\n",
        "\n",
        "    # Print the current number of unique products in the used data\n",
        "    print(\"current_test_number_unique_products:\", current_test_number_unique_products)\n",
        "\n",
        "    # Calculate the number of possible pairs for the used data\n",
        "    current_possible_pairs = current_test_number_unique_products * (current_test_number_unique_products - 1) // 2\n",
        "    print(\"current_possible_pairs:\", current_possible_pairs)\n",
        "\n",
        "\n",
        "    ####################################################################################\n",
        "    test_model_words_data_novel_BOTH = extract_model_words_novel_BOTH(current_test_data)\n",
        "    #test_model_words_data_original_BOTH = extract_model_words_original_BOTH(current_test_data)\n",
        "\n",
        "    test_binary_matrix, test_model_words_list = get_binary_matrix(current_test_data, test_model_words_data_novel_BOTH) ######################################################################\n",
        "    #test_binary_matrix, test_model_words_list = get_binary_matrix(current_test_data, test_model_words_data_original_BOTH)\n",
        "    #test_binary_matrix, test_model_words_list = get_binary_matrix_with_brand_influence(current_test_data, test_model_words_data_novel_BOTH, 2, current_id_test_data_sets)\n",
        "\n",
        "    #test_binary_matrix = filter_binary_matrix(test_binary_matrix) ######################################################### Cut columns (model words) where sum = 1\n",
        "\n",
        "    test_num_model_words = test_binary_matrix.shape[1]\n",
        "    print(\"test num_model_words\")\n",
        "    print(test_num_model_words, len(test_model_words_list))\n",
        "\n",
        "    k_test = 900 #num_model_words // 2  # Size of signature vector is half the binary vector size !! change here\n",
        "\n",
        "    prime_test = nextprime(3*test_num_model_words)\n",
        "    print(\"prime test:\")\n",
        "    print(prime_test)\n",
        "\n",
        "    test_signature_matrix = minhash_signature_matrix(test_binary_matrix, k_test, prime_test)  # FILTERED OR BINARY!!!!!!!!!!!!!!!! change also here\n",
        "    #print(\"test Signature Matrix:\")\n",
        "    #print(test_signature_matrix)\n",
        "    print(\"test Sginature matrix sizes: \", test_signature_matrix.shape)\n",
        "\n",
        "    for b_index, b in enumerate(test_b_values):\n",
        "\n",
        "        # Calculate r and the corresponding threshold\n",
        "        r_test = k_test // b\n",
        "        threshold = (1 / b) ** (1 / r)\n",
        "        print(f\"b: {b}, r: {r_test}, threshold: {threshold}\")\n",
        "\n",
        "        # Perform LSH to find candidate pairs\n",
        "        test_candidate_pairs = lsh(b, r_test, test_signature_matrix)\n",
        "        #print(f\"Candidate pairs: {candidate_pairs}\")\n",
        "        print(f\"Number test candidate pairs: {len(test_candidate_pairs)}\")\n",
        "\n",
        "        number_comparisons = len(test_candidate_pairs) # for test ONLY\n",
        "        fraction_of_comparisons = number_comparisons/current_possible_pairs # for teset ONLY\n",
        "        print(\"Number of comparisons:\", number_comparisons)\n",
        "\n",
        "        fraction_of_comparisons = number_comparisons/current_possible_pairs\n",
        "\n",
        "        # Perform hierarchical clustering\n",
        "        clusters_single = hierarchical_clustering(current_test_data, test_binary_matrix, b, r_test, test_signature_matrix, 'single')\n",
        "\n",
        "        # Get pairs from clusters\n",
        "        single_cluster_pairs = get_pairs_from_clusters(clusters_single)\n",
        "\n",
        "        # Evaluate performance\n",
        "        single_f1_measure, single_pair_quality, single_pair_completeness, single_f1_star = evaluate_performance(test_candidate_pairs, single_cluster_pairs, test_true_pairs, current_possible_pairs)\n",
        "\n",
        "        # Store the performance metrics for this bootstrap and this b value\n",
        "        # Store the performance metrics in the corresponding matrix entry\n",
        "        test_results_matrix[b_index][bootstrap_index][\"f1_measures\"].append(single_f1_measure)\n",
        "        test_results_matrix[b_index][bootstrap_index][\"f1_stars\"].append(single_f1_star)\n",
        "        test_results_matrix[b_index][bootstrap_index][\"pair_qualities\"].append(single_pair_quality)\n",
        "        test_results_matrix[b_index][bootstrap_index][\"pair_completenesses\"].append(single_pair_completeness)\n",
        "        # Add fraction of comparisons to results_matrix\n",
        "        test_results_matrix[b_index][bootstrap_index][\"fraction_of_comparisons\"] = fraction_of_comparisons\n",
        "\n",
        "# Calculate the average results across bootstraps for each b\n",
        "test_final_results = []\n",
        "for b_index, b in enumerate(test_b_values):\n",
        "    avg_f1_measure = np.mean([np.mean(test_results_matrix[b_index][bootstrap][\"f1_measures\"]) for bootstrap in range(n_bootstraps)])\n",
        "    avg_f1_star = np.mean([np.mean(test_results_matrix[b_index][bootstrap][\"f1_stars\"]) for bootstrap in range(n_bootstraps)])\n",
        "    avg_pair_quality = np.mean([np.mean(test_results_matrix[b_index][bootstrap][\"pair_qualities\"]) for bootstrap in range(n_bootstraps)])\n",
        "    avg_pair_completeness = np.mean([np.mean(test_results_matrix[b_index][bootstrap][\"pair_completenesses\"]) for bootstrap in range(n_bootstraps)])\n",
        "    avg_fraction_of_comparisons = np.mean([test_results_matrix[b_index][bootstrap][\"fraction_of_comparisons\"] for bootstrap in range(n_bootstraps)])\n",
        "    #print(\"for this b, we  get this avg g1 star \", b, avg_f1_star)\n",
        "\n",
        "    # Store the averaged results for the current b\n",
        "    test_final_results.append({\n",
        "        \"b\": b,\n",
        "        \"avg_f1_measure\": avg_f1_measure,\n",
        "        \"avg_f1_star\": avg_f1_star,\n",
        "        \"avg_pair_quality\": avg_pair_quality,\n",
        "        \"avg_pair_completeness\": avg_pair_completeness,\n",
        "        \"fraction_of_comparisons\": avg_fraction_of_comparisons,\n",
        "    })\n",
        "\n",
        "\n",
        "#print(\"test \", test_final_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om_ibTet6bmX"
      },
      "source": [
        "# Up Main Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVU_bElv6oXb"
      },
      "source": [
        "# Graphs (Results latest test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgrpgDXg6qvP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Convert results to a DataFrame for easier plotting\n",
        "results_df = pd.DataFrame(test_final_results)\n",
        "\n",
        "# Generate Graphs\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Graph 1: Fraction of Comparisons vs Average F1 Measure\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(results_df['fraction_of_comparisons'], results_df['avg_f1_measure'], marker='o')\n",
        "plt.xlabel('Fraction of Comparisons')\n",
        "plt.ylabel('Average F1 Measure')\n",
        "plt.title('Fraction of Comparisons vs F1 Measure')\n",
        "\n",
        "# Graph 2: Fraction of Comparisons vs Average F1* Measure\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(results_df['fraction_of_comparisons'], results_df['avg_f1_star'], marker='o')\n",
        "plt.xlabel('Fraction of Comparisons')\n",
        "plt.ylabel('Average F1* Measure')\n",
        "plt.title('Fraction of Comparisons vs F1* Measure')\n",
        "\n",
        "# Graph 3: Fraction of Comparisons vs Average Pair Quality\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(results_df['fraction_of_comparisons'], results_df['avg_pair_quality'], marker='o')\n",
        "plt.xlabel('Fraction of Comparisons')\n",
        "plt.ylabel('Average Pair Quality')\n",
        "plt.title('Fraction of Comparisons vs Pair Quality')\n",
        "\n",
        "# Graph 4: Fraction of Comparisons vs Average Pair Completeness\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(results_df['fraction_of_comparisons'], results_df['avg_pair_completeness'], marker='o')\n",
        "plt.xlabel('Fraction of Comparisons')\n",
        "plt.ylabel('Average Pair Completeness')\n",
        "plt.title('Fraction of Comparisons vs Pair Completeness')\n",
        "\n",
        "# # Graph 5: Fraction of Comparisons vs Average F1 Measure & F1* Measure\n",
        "# plt.subplot(2, 3, 5)\n",
        "# plt.plot(results_df['fraction_of_comparisons'], results_df['avg_f1_measure'], marker='o', label='F1 Measure')\n",
        "# plt.plot(results_df['fraction_of_comparisons'], results_df['avg_f1_star'], marker='o', label='F1* Measure', linestyle='--')\n",
        "# plt.xlabel('Fraction of Comparisons')\n",
        "# plt.ylabel('F1 Measures')\n",
        "# plt.title('Fraction of Comparisons vs F1 & F1* Measures')\n",
        "#plt.legend()\n",
        "\n",
        "# Adjust layout and show\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyNV08aCWXY8wHPY132DD09u"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}